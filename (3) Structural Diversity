# This code is based on the work of Morgenroth et al. (2020) (DOI: 10.3390/f11020135)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import gaussian_kde
import matplotlib.lines as mlines

df = pd.read_csv("cleaned_master.csv", low_memory=False)
excluded_cities = ['Maple Ridge', 'New Westminster', 'Peterborough', 'Halifax']
df = df[~df['City'].isin(excluded_cities)]

# Ensure DBH is numeric and drop NaN values
df['DBH'] = pd.to_numeric(df['DBH'], errors='coerce')
df = df.dropna(subset=['DBH'])

# Create bins
bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, np.inf]
n_classes = 17 # Number of DBH classes for each city
bin_midpoints = [(bins[i] + bins[i+1]) / 2 for i in range(len(bins)-1)]

# Define cities and prepare lists for all midpoints and proportions
cities = df['City'].unique()
all_midpoints = []
all_proportions = []

## Find Median DBH for each value of City
median_dbh_per_city = df.groupby('City')['DBH'].median().reset_index()
print(median_dbh_per_city)


## Create histograms for the DBH distributions of each city (Urban Forest Diameter Class Distributions)
# Loop over each city to create histograms and curve plots
for city in cities:
    city_data = df[df['City'] == city]

    if len(city_data) == 0:
        continue  # Skip if there are no valid DBH values for the city

    # Create histogram with custom bins
    plt.figure(figsize=(8, 6))

    # Restrict x-axis to maximum of 150 cm
    sns.histplot(city_data['DBH'], bins=bins, kde=False, color='skyblue')

    # Fit and plot the KDE (Kernel Density Estimate) curve
    kde = gaussian_kde(city_data['DBH'])

    # Restrict the x-range for the KDE to be within the defined bin range
    x_range = np.linspace(0, 150, 1000)  # Limit the KDE to 150 cm
    plt.plot(x_range, kde(x_range) * len(city_data['DBH']) * (bins[1] - bins[0]), color='red', lw=2)

    # Set x-axis limit to match the bins
    plt.xlim(0, 150)

    # Add titles and labels
    plt.title(f'DBH Histogram with Curve for {city}')
    plt.xlabel('DBH (cm)')
    plt.ylabel('Frequency')

    # Show the plot
    plt.show()

## Comparison of Diameter Class Distributions Against Richards Distribution
plt.figure(figsize=(12, 6)) #

# Richards data points and line function
richards_midpoints = [10, 30, 50, 70]
richards_values = [40, 30, 20, 10]
x = np.linspace(0, 100, 6)
y = -0.5 * x + 45

# Plot Richards data and line
plt.plot(richards_midpoints, richards_values, 'bs-', label='Richards Data')
plt.plot(x, y, 'b-', label='Line: y = -0.5x + 45')

# Loop through each city and calculate DBH proportions
for city in cities:
    city_data = df[df['City'] == city]

    # Bin the DBH values and calculate the proportion in each bin
    city_data['DBH_bins'] = pd.cut(city_data['DBH'], bins=bins)
    bin_counts = city_data['DBH_bins'].value_counts().sort_index()

    # Calculate the proportion of the total population in each bin
    proportions = bin_counts / bin_counts.sum() * 100  # Convert to percentages

    # Plot the proportions for this city (only markers, no lines)
    plt.plot(bin_midpoints, proportions, 'o', markersize=4, markerfacecolor='k', markeredgewidth=0, label=f'{city} Data')

# Create a line of best fit
x_fit = np.linspace(0, 150, 1000)
y_fit = 41.543 * np.exp(-0.039 * x_fit)
plt.plot(x_fit, y_fit, 'k-', label='Line of Best Fit')

# Legend
inventory_data_handle = mlines.Line2D([], [], color='k', marker='o', linestyle='None', markersize=8, label='Inventory Data')
best_fit_handle = mlines.Line2D([], [], color='k', linestyle='-', markersize=8, label='Line of Best Fit')
richards_handle = mlines.Line2D([], [], color='b', marker='s', linestyle='-', markersize=8, label='Richards')
plt.legend(handles=[inventory_data_handle, best_fit_handle, richards_handle])

# Customize plot
plt.xlim(0, 150)
plt.ylim(0, 70)
plt.title('Aggregated DBH Distribution and Line of Best Fit')
plt.xlabel('DBH (cm)')
plt.ylabel('Proportion of Total Population (%)')
plt.grid(False)
plt.show()


## Structural Diversity Index
def calculate_shannon_wiener(city_data, bins):
    # Classify trees into DBH classes using binning
    dbh_classes = pd.cut(city_data['DBH'], bins=bins, labels=range(1, len(bins)))

    # Calculate the proportion of trees in each class
    class_counts = dbh_classes.value_counts(normalize=True).sort_index()

    # Check for empty upper bins and adjust the number of classes
    last_non_empty_class = class_counts[class_counts > 0].index[-1]
    valid_bins = bins[:last_non_empty_class + 1]  # Include up to the last non-empty class

    # Reclassify using valid bins
    dbh_classes = pd.cut(city_data['DBH'], bins=valid_bins, labels=range(1, len(valid_bins)))
    class_counts = dbh_classes.value_counts(normalize=True).sort_index()

    # Filter out zero proportions to avoid log(0)
    class_proportions = class_counts[class_counts > 0]

    # Calculate the Shannon-Wiener index (H)
    H = -np.sum(class_proportions * np.log(class_proportions))

    # Calculate H_max (maximum possible diversity)
    H_max = np.log(len(valid_bins) - 1)  # Use the number of non-empty bins

    return H, H_max


# Calculate Shannon-Wiener index for each city
city_results = []

cities = df['City'].unique()
for city in cities:
    city_data = df[df['City'] == city]

    if len(city_data) == 0:
        continue  # Skip if there are no valid DBH values for the city

    H, H_max = calculate_shannon_wiener(city_data, bins)

    # Store the result for the city
    city_results.append({
        'City': city,
        'Shannon-Wiener Index (H)': H,
        'Maximum Diversity (H_max)': H_max
    })


# Convert results to a DataFrame for easy viewing
Structural_Diversity_Index_df = pd.DataFrame(city_results)
print(Structural_Diversity_Index_df)
